{
  "hash": "b71b50d8f830ccd5da514ce41bd0891d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Linear Regression for Gentle Souls\"\nslug: \"my-new-post\"\nauthor: \"John T. Miller\"\ndate: \"2025-06-17\"\ncategories: [R, code, regression, analysis]\nimage: \"image1.jpg\"\n---\n\n![](pupply.jpg)\n\n# **Linear Regression in R for Gentle Souls**\n\nIn statistics, linear regression is a linear approach for modelling the relationship between a response and one or more explanatory variables. It is fairly intuitive and works fairly well in the cases where a linear relationship exists between variables.\n\nLinear regression is a statistical technique used to model the relationship between a dependent variable (also known as the response variable) and one or more independent variables (also known as predictor variables). The goal of linear regression is to find the best linear relationship between the dependent variable and the independent variables.\n\nIn simple linear regression, there is only one independent variable. The relationship between the dependent variable and the independent variable can be represented by a straight line, hence the term “linear” regression. The equation for a simple linear regression model is:\n\nY = a + bX + e\n\nWhere:\n\n-   Y is the dependent variable\n\n-   X is the independent variable\n\n-   a is the intercept (the value of Y when X=0)\n\n-   b is the slope (the change in Y for a one-unit change in X)\n\n-   e is the error term (the difference between the predicted value of Y and the actual value of Y)\n\nIn multiple linear regression, there are multiple independent variables. The equation for a multiple linear regression model is similar to the simple linear regression model, but with multiple independent variables:\n\nY = a + b1X1 + b2X2 + … + bnXn + e\n\nWhere:\n\n-   Y is the dependent variable\n\n-   X1, X2, …, Xn are the independent variables\n\n-   a is the intercept\n\n-   b1, b2, …, bn are the slopes\n\n-   e is the error term\n\nTo build a linear regression model in R, you can use the `lm()` function. Here's an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\ninstall.packages('ggplot2')\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nInstalling package into '/cloud/lib/x86_64-pc-linux-gnu-library/4.4'\n(as 'lib' is unspecified)\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Load the iris dataset\ndata(iris)\n\n# Fit a simple linear regression model\nmodel <- lm(Petal.Width ~ Petal.Length, data = iris)\n\n# Show the model summary\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56515 -0.12358 -0.01898  0.13288  0.64272 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.363076   0.039762  -9.131  4.7e-16 ***\nPetal.Length  0.415755   0.009582  43.387  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2065 on 148 degrees of freedom\nMultiple R-squared:  0.9271,\tAdjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot with regression line\nggplot(iris, aes(x = Petal.Length, y = Petal.Width)) +\n  geom_point(color = \"blue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Simple Linear Regression: Petal.Length vs Petal.Width\",\n       x = \"Petal Length\",\n       y = \"Petal Width\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nWe first load the data and build a simple linear regression model using the `lm()` function. We then view the summary of the model to see the coefficients, R-squared value, and other statistics. We can then make predictions using the model by creating a new data frame with the independent variable values we want to predict for, and using the `predict()` function to generate the predicted values.\n\n# **Final Thought**\n\nBe advised that a linear relationship does not always exist between two variables, yet they are related. Linear regression is just one tool of many that can be utilized to describe the reality of your data.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}